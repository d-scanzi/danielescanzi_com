{
  "hash": "9ad962ee6ca79681f2ae5b94c1f15ca6",
  "result": {
    "markdown": "---\ntitle: \"Bayesian Engines\"\nformat:\n    revealjs: \n        theme: dark\n        css: my_style.css\n---\n\n\n## Last week\n\n::: {.v-center-container}\n> 2E4. The Bayesian statistician Bruno de Finetti (1906--1985) began his\n> 1973 book on probability theory with the declaration: \"PROBABILITY\n> DOES NOT EXIST.\" The capitals appeared in the original, so I imagine\n> de Finetti wanted us to shout this statement. What he meant is that\n> probability is a device for describing uncertainty from the\n> perspective of an observer with limited knowledge; it has no objective\n> reality. Discuss the globe tossing example from the chapter, in light\n> of this statement. What does it mean to say \"the probability of water\n> is 0.7\"?\n\n:::\n\n# Discussion {.center}\n\n## Discussion\n\n::: {.v-center-container}\n> In contrast, Bayesian estimates are valid for any sample size. This\n> does not mean that more data isn't helpful---it certainly is. Rather,\n> the estimates have a clear and valid interpretation, no matter the\n> sample size. But the price for this power is dependency upon the\n> initial plausibilities, the prior. If the prior is a bad one, then the\n> resulting inference will be misleading.\n\n::: \n\n# Video {.center}\n\n## Video\n\n<iframe width=\"95%\" height=\"70%\" src=\"https://www.youtube.com/embed/guTdrfycW2Q?start=2638\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen>\n\n</iframe>\n\nClick [here](https://youtu.be/guTdrfycW2Q?t=2638)\n\n## Post-video discussion \n\n::: {.v-center-container}\nWhy sampling?\n:::\n\n## Implement the engines\n\n1.  Draw cards\n2.  Define grid resolution\n3.  Initialise grid\n4.  Define prior\n5.  Define Likelihood\n6.  Compute posterior\n7.  Plot!\n\n## Draw cards\n\n::: columns\n::: {.column width=\"40%\"}\n:::\n\n::: {.column width=\"60%\"}\n``` {.r code-line-numbers=\"1-2\"}\n# Store draws (1 = R, 0 = B)\ndraws \n```\n:::\n:::\n\n## Draw cards\n\n::: columns\n::: {.column width=\"40%\"}\n:::\n\n::: {.column width=\"60%\"}\n``` {.r code-line-numbers=\"1-2\"}\n# Store draws (1 = R, 0 = B)\ndraws <- c(1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1)\n```\n:::\n:::\n\n## Grid resolution\n\n:::: columns\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\npoints_plot <- tibble(\n    x = seq(0, 1, by = .4),\n    y = dnorm(x, mean = 0.3, sd = 0.2)\n)\n\nline_plot <- tibble(\n    x = seq(0, 1, by = .01),\n    y = dnorm(x, mean = 0.3, sd = 0.2)\n)\n\npoints_plot %>% \n    ggplot(aes(x = x, y = y)) +\n    geom_line(data = line_plot, aes(x = x, y = y), alpha = .7, size = 1.5, colour = \"black\") +\n    geom_point(colour = \"red\", size = 4) +\n    geom_vline(xintercept = points_plot$x, colour = \"red\", alpha = .8) +\n    geom_hline(yintercept = points_plot$y, colour = \"red\", alpha = .8) +\n    scale_x_continuous(breaks = seq(0 , 1, by = .05)) +\n    theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](slide_02_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\npoints_plot %>% \n    ggplot(aes(x = x, y = y)) +\n    geom_path(size = 1.5) +\n    geom_point(colour = \"red\", size = 4) +\n    theme_minimal()\n```\n\n::: {.cell-output-display}\n![](slide_02_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n:::\n\n::::\n\n## Grid resolution\n\n:::: columns\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\npoints_plot <- tibble(\n    x = seq(0, 1, by = .2),\n    y = dnorm(x, mean = 0.3, sd = 0.2)\n)\n\nline_plot <- tibble(\n    x = seq(0, 1, by = .01),\n    y = dnorm(x, mean = 0.3, sd = 0.2)\n)\n\npoints_plot %>% \n    ggplot(aes(x = x, y = y)) +\n    geom_line(data = line_plot, aes(x = x, y = y), alpha = .7, size = 1.5, colour = \"black\") +\n    geom_point(colour = \"red\", size = 4) +\n    geom_vline(xintercept = points_plot$x, colour = \"red\", alpha = .8) +\n    geom_hline(yintercept = points_plot$y, colour = \"red\", alpha = .8) +\n    scale_x_continuous(breaks = seq(0 , 1, by = .05)) +\n    theme_minimal()\n```\n\n::: {.cell-output-display}\n![](slide_02_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\npoints_plot %>% \n    ggplot(aes(x = x, y = y)) +\n    geom_path(size = 1.5) +\n    geom_point(colour = \"red\", size = 4) +\n    theme_minimal()\n```\n\n::: {.cell-output-display}\n![](slide_02_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n:::\n\n::::\n## Grid resolution\n\n:::: columns\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\npoints_plot <- tibble(\n    x = seq(0, 1, by = .05),\n    y = dnorm(x, mean = 0.3, sd = 0.2)\n)\n\nline_plot <- tibble(\n    x = seq(0, 1, by = .01),\n    y = dnorm(x, mean = 0.3, sd = 0.2)\n)\n\npoints_plot %>% \n    ggplot(aes(x = x, y = y)) +\n    geom_line(data = line_plot, aes(x = x, y = y), alpha = .7, size = 1.5, colour = \"black\") +\n    geom_point(colour = \"red\", size = 4) +\n    geom_vline(xintercept = points_plot$x, colour = \"red\", alpha = .8) +\n    geom_hline(yintercept = points_plot$y, colour = \"red\", alpha = .8) +\n    scale_x_continuous(breaks = seq(0 , 1, by = .05)) +\n    theme_minimal()\n```\n\n::: {.cell-output-display}\n![](slide_02_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\npoints_plot %>% \n    ggplot(aes(x = x, y = y)) +\n    geom_path(size = 1.5) +\n    geom_point(colour = \"red\", size = 4) +\n    theme_minimal()\n```\n\n::: {.cell-output-display}\n![](slide_02_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n:::\n\n::::\n\n## Grid resolution\n\n``` {.r code-line-numbers=\"3-4\"}\n# Store draws (1 = R, 0 = B)\ndraws <- c(1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1)\n# We need to define how coarse the grid is\ngrid_points <- \n```\n\n## Grid resolution\n\n``` {.r code-line-numbers=\"3-4\"}\n# Store draws (1 = R, 0 = B)\ndraws <- c(1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1)\n# We need to define how coarse the grid is\ngrid_points <- 100\n```\n\n## Implementing Grid Approximation\n\n``` {.r code-line-numbers=\"7-16\"}\n# Store draws (1 = R, 0 = B)\ndraws <- c(1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1)\n\n# We need to define how coarse the grid is\ngrid_points <- 100\n\n# Define Bayes theorem through grid approximation\ngrid_posterior <- tibble(\n\n    # GRID OF PARAMETER VALUES\n    \n    # UNINFORMATIVE PRIOR\n    \n    # LIKELIHOOD\n    \n    # POSTERIOR\n)\n```\n\n## Grid of parameter values\n\n::: columns\n::: {.column width=\"40%\"}\nA grid is simply a selection of values that the parameter(s) of interest\ncan take. It's a way to discretize a continuous distribution\n:::\n\n::: {.column width=\"60%\"}\n``` {.r code-line-numbers=\"10-13\"}\n# Store draws (1 = R, 0 = B)\ndraws <- c(1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1)\n\n# We need to define how coarse the grid is\ngrid_points <- 100\n\n# Define Bayes theorem through grid approximation\ngrid_posterior <- tibble(\n\n    # GRID OF PARAMETER VALUES\n    grid = seq(from       = 0, \n               to         = 1, \n               length.out = grid_points),\n    # UNINFORMATIVE PRIOR\n    \n    # LIKELIHOOD\n    \n    # POSTERIOR\n)\n```\n:::\n:::\n\n## Uninformative prior\n\n::: columns\n::: {.column width=\"40%\"}\nAn uninformative prior is a uniform distribution where every parameter\nvalue has the same probability than the others\n:::\n\n::: {.column width=\"60%\"}\n``` {.r code-line-numbers=\"14-15\"}\n# Store draws (1 = R, 0 = B)\ndraws <- c(1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1)\n\n# We need to define how coarse the grid is\ngrid_points <- 100\n\n# Define Bayes theorem through grid approximation\ngrid_posterior <- tibble(\n\n    # GRID OF PARAMETER VALUES\n    grid = seq(from       = 0, \n               to         = 1, \n               length.out = grid_points),\n    # UNINFORMATIVE PRIOR\n    prior      = 1,\n    # LIKELIHOOD\n    \n    # POSTERIOR\n)\n```\n:::\n:::\n\n## Likelihood\n\n::: columns\n::: {.column width=\"40%\"}\nThe probability of the data given a specific parameter value\n\\[P(D\\|p)\\]. Our data consist of red and black cards, so we are asking\n*what is the probability of observing N red cards in N draws?*\n:::\n\n::: {.column width=\"60%\"}\n``` {.r code-line-numbers=\"16-17\"}\n# Store draws (1 = R, 0 = B)\ndraws <- c(1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1)\n\n# We need to define how coarse the grid is\ngrid_points <- 100\n\n# Define Bayes theorem through grid approximation\ngrid_posterior <- tibble(\n\n    # GRID OF PARAMETER VALUES\n    grid = seq(from       = 0, \n               to         = 1, \n               length.out = grid_points),\n    # UNINFORMATIVE PRIOR\n    prior      = 1,\n    # LIKELIHOOD\n    likelihood = dbinom(sum(draws), size = length(draws), prob = grid),\n    # POSTERIOR\n)\n```\n:::\n:::\n\n## Posterior\n\n::: columns\n::: {.column width=\"40%\"}\nWe have the grid, the prior and the likelihood, let's apply Bayes'\ntheorem\n:::\n\n::: {.column width=\"60%\"}\n``` {.r code-line-numbers=\"18-19\"}\n# Store draws (1 = R, 0 = B)\ndraws <- c(1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1)\n\n# We need to define how coarse the grid is\ngrid_points <- 100\n\n# Define Bayes theorem through grid approximation\ngrid_posterior <- tibble(\n\n    # GRID OF PARAMETER VALUES\n    grid = seq(from       = 0, \n               to         = 1, \n               length.out = grid_points),\n    # UNINFORMATIVE PRIOR\n    prior      = 1,\n    # LIKELIHOOD\n    likelihood = dbinom(sum(draws), size = length(draws), prob = grid),\n    # POSTERIOR\n    posterior  = (prior * likelihood) / sum(prior * likelihood)\n)\n```\n:::\n:::\n\n## Plot!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Store draws (1 = R, 0 = B)\ndraws <- c(1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1)\n\n# We need to define how coarse the grid is\ngrid_points <- 100\n\n# Define Bayes theorem through grid approximation\ngrid_posterior <- tibble(\n\n    # GRID OF PARAMETER VALUES\n    grid = seq(from       = 0, \n               to         = 1, \n               length.out = grid_points),\n    # UNINFORMATIVE PRIOR\n    prior      = 1,\n    # LIKELIHOOD\n    likelihood = dbinom(sum(draws), size = length(draws), prob = grid),\n    # POSTERIOR\n    posterior  = (prior * likelihood) / sum(prior * likelihood)\n) %>% \n    pivot_longer(cols = !grid,\n                 names_to = \"distribution\",\n                 values_to = \"plausibility\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_posterior %>% \n    ggplot(aes( x = grid, y = plausibility, colour = distribution)) +\n    geom_point() +\n    theme_minimal() +\n    facet_grid(distribution~., scales = \"free_y\")\n```\n\n::: {.cell-output-display}\n![](slide_02_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n# Exercises {.center}\n\n## Exercises\n\n::: {.v-center-container}\n\n>2M1. Recall the globe tossing model from the chapter. Compute and plot the grid approximate posterior distribution for each of the following sets of observations. In each case, assume a uniform prior for p. \n(1) W, W, W \n(2) W, W, W, L \n(3) L, W, W, L, W, W, W\n\n:::\n\n## Exercises\n\n::: {.v-center-container}\n\n>2M2. Now assume a prior for p that is equal to zero when p < 0.5 and is a positive constant when p ≥ 0.5. Again compute and plot the grid approximate posterior distribution for each of the sets of observations in the problem just above.\n\n:::\n\n## Discussion\n\n::: {.v-center-container}\n\n> If you don't have a strong argument for any particular prior, then try\n> different ones. Because the prior is an assumption, it should be\n> interrogated like other assumptions: by altering it and checking how\n> sensitive inference is to the assumption. No one is required to swear\n> an oath to the assumptions of a model, and no set of assumptions\n> deserves our obedience.\n\n:::\n\n# Next time {.center}\n\n## Next time\n\n* Finish reading chapter 2 (from 2.3 to 2.5)\n* Exercise: 2E1, 2E2, 2E3, 2M3,  2M4,  2M5,  2M6,  2M7\n\n",
    "supporting": [
      "slide_02_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}