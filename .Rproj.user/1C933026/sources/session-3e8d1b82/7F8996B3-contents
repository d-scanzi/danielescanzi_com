---
title: "Brain fingerprinting - Lab 3"
author: "Daniele Scanzi"
date: "2023-08-05"
output: html_document
---

## General instructions

This document contains code that will simulate the brain fingerprinting technique we discussed last week. Every time you see a block like the following,

```{r}
# Some code here
```


you need to click on the green play button on the right to run the code. Please, read through the instructions provided before each code block. Sometimes you will need to modify the code before running it. 

Give it a try by running the following block

```{r}
# Load packages for the analysis
library(tidyverse)

# Functions useful for later (to keep some parts clean)

# Setting up the data 
set_up_data <- function(df) {
    df_cleaned <- df %>% 
    # Make dataset in long format
    pivot_longer(cols = !c(V1,V2),
                 names_to = 'tmp',
                 values_to = 'voltage') %>% 
    # Rename columns in a way that makes sense
    rename('condition'= V1,
           'trial'= V2) %>% 
    # Add time and adjust it so that 0 is the stimulus onset
    group_by(condition, trial) %>% 
    mutate(time = 1:n(),
           time = time - 1000) %>% 
    # Remove tmp column (useless)
    select(!tmp) %>% 
        ungroup()
    
    return(df_cleaned)
}
```


## Load the data]

In this simulation, we have applied the brain fingerprinting technique to three people to investigate which one committed a crime. The EEG recordings have been processed (cleaned) for you but have not been analysed.

These lines of code will load the data from the three participant. Try to run it

```{r}
# These lines will load the data
p1_raw <- read.csv('data/p001_fz_data.csv', header = FALSE) # First participant
p2_raw <- read.csv('data/p002_fz_data.csv', header = FALSE) # Second participant
p3_raw <- read.csv('data/p003_fz_data.csv', header = FALSE) # Third participant

# These lines will set up the data for later
p1_data <- set_up_data(p1_raw)
p2_data <- set_up_data(p2_raw)
p3_data <- set_up_data(p3_raw)

# As different datasets and conditions have different number of trials, let's 
# reduce the number of trials to 100 for each condition. This is sufficient here 
# as the data are simulated
p1_data <- filter(.data = p1_data, trial %in% 1:100)
p2_data <- filter(.data = p2_data, trial %in% 1:100)
p3_data <- filter(.data = p3_data, trial %in% 1:100)

```

From now on we will work with `p1_data`, `p2_data` and `p3_data`.

## Why averaging?

EEG is noisy and despite we try to remove as much noise as possible, this is usually not enough to observe an ERP at the single trial level. Let's check this together. In the following piece of code, you can set the number of the trial you want to look at.

```{r}
# Set a number between 1 and 100
trialN <- 45

# Change the dataset to plot different participants.
# To look at the baseline (if interested), remove `time >= 0` from filter
p1_data %>% 
    filter(trial == trialN, 
           time >= 0) %>% 
    ggplot(aes(x = time, y = voltage, colour = condition)) +
    geom_line(linewidth = 1.2) +
    geom_vline(xintercept = 0) +
    scale_x_continuous(breaks = c(-1000, -500, seq(0, 1200, 200))) +
    labs(
        x = 'Time(ms)',
        y = expression(paste('Voltage (', mu, 'V)')),
        title = 'Single trial plot'
    ) +
    theme_minimal()
```
We can also plot all the trials together for each condition in what we call a *butterfly plot*. In the code below, change the condition and the dataset to explore the data

```{r}
condition_name <- 'target'
p1_data %>% 
    filter(condition == condition_name,
           time >= 0) %>% 
    ggplot(aes(x = time, y = voltage, colour = as.factor(trial))) +
    geom_line(linewidth = 1.2, alpha = .2) +
    geom_vline(xintercept = 0) +
    #scale_x_continuous(breaks = c(-1000, -500, seq(0, 1200, 200))) +
    labs(
        x = 'Time(ms)',
        y = expression(paste('Voltage (', mu, 'V)')),
        title = 'Butterfly plot'
    ) +
    theme_minimal() +
    theme(legend.position = "none")
```
Note the variability from trial to trial. Hopefully, somewhere inside this noisy mess there are some patterns that occurred in every trial (ERP). The aim of averaging is to remove all the variability while preserving recurring patterns (as long as they happen around the same time).

NOTE: as this data do not reflect a real task, it is noisier than usual. Normally, you might be able to see a hint of an effect. 

Now, we will average all the trials for each condition. Note, the average is conducted at each time point.

```{r}
# Compute averages
p1_average <- p1_data %>% 
    group_by(condition, time) %>% 
    summarise(average = mean(voltage)) %>% 
    ungroup()

p2_average <- p2_data %>% 
    group_by(condition, time) %>% 
    summarise(average = mean(voltage)) %>% 
    ungroup()

p3_average <- p3_data %>% 
    group_by(condition, time) %>% 
    summarise(average = mean(voltage)) %>% 
    ungroup()
```

## Check the averages

Now that we have averaged across trials, we are ready to look at the data and decide who committed the crime. Run the code below to look at suspect 1 and decide whether they are guilty or not. Remember to provide a reason for your judgment.
Once you are done with it, change the data to suspect 2 (`p2_average`) and suspect 3 (`p3_average`).


```{r}
p1_average %>% 
    filter(time >= 0) %>% 
    ggplot(aes(x = time, y = average, colour = condition)) +
    geom_line(linewidth = 1.2) +
    geom_vline(xintercept = 0) +
    scale_x_continuous(breaks = c(-1000, -500, seq(0, 1200, 200))) +
    labs(
        x = 'Time(ms)',
        y = expression(paste('Voltage (', mu, 'V)')),
        title = 'Grand averages'
    ) +
    theme_minimal()
```

## Can we qunatify this numerically?

One way to measure the amplitude of the P300 in each condition, is to average the voltage in a time-window we believe the P300 appears. We will do that here. 

In the following code, define a time range you believe the P300 is shown. To check other datasets, change the data to use

```{r}
# Define a time range (start, stop)
p300_time <- c(100, 1000)

# The following code computes the average amplitudes in the time range you defined
p300_averages <- p1_average %>% 
    filter(time >= p300_time[1] & time <= p300_time[2]) %>% 
    group_by(condition) %>% 
    summarise(average_amplitude = mean(average))
    

# Plot the window with values
p1_average %>% 
    filter(time >= 0) %>% 
    ggplot(aes(x = time, y = average, colour = condition)) +
    geom_line(linewidth = 1.2) +
    geom_vline(xintercept = 0) +
    annotate('rect', xmin = p300_time[1], xmax = p300_time[2], ymin = -Inf, ymax = +Inf, fill = 'gray', alpha = .5) +
    annotate('text', x = 1000, y = 3.5, label = paste('irrelevant:', round(p300_averages[p300_averages$condition == 'irrelevant', 2], 3))) +
    annotate('text', x = 1000, y = 3, label = paste('target:', round(p300_averages[p300_averages$condition == 'target', 2], 3))) +
    annotate('text', x = 1000, y = 2.5, label = paste('probe:', round(p300_averages[p300_averages$condition == 'probe', 2], 3))) +
    scale_x_continuous(breaks = c(-1000, -500, seq(0, 1200, 200))) +
    labs(
        x = 'Time(ms)',
        y = expression(paste('Voltage (', mu, 'V)')),
        title = 'P300 average window'
    ) +
    theme_minimal()
    
```
