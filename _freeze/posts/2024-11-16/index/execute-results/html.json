{
  "hash": "35bcbfc64abaf21b1dfbfdea9b9f6fb0",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Fourier Transformation and Edges\nfig-cap-location: top\n---\n\n\nThe Fourier transform is an extremely common tool in many sciences. In neuroscience, it is used to analyse the frequency domain of data collected through a variety of different techniques: electroencephalography, magnetoencephalography, electrocardiography, skin conductance, etc... Basically any time-series data. When learning and reading about frequency analyses in this domain, there is one term that pops op over and over again\n\n<center><i><b> EDGE EFFECTS </center></i></b>\n\nI first encountered them when I was learning how to preprocess (aka clean) EEG data for my honours project. I wanted to filter the data to get rid of some low frequency and high frequency components and I keep finding people online warning about the importance to consider edge artefacts. I didn't know what they were, I could only understand that if your data changes abruptly in the time-domain, there could be artefacts introduced in the frequency domain when. At the time I was under time pressure to finish the project, so I trusted the suggestions, verified that my data looked fine after filtering, and then moved on. It is only recently that I went back to really delve into this topic and I started to appreciate the complexity of edges - or better, the complexity of dealing with edges.\n\nLet's get started by visualizing an edge.\n\n::: {#2adf88cc .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport copy\nfrom scipy.fft import fft, fftfreq, fftshift\nfrom matplotlib import pyplot as plt\n\nplt.style.use('seaborn-v0_8-paper')\n\n## Create signal\nsampling_rate_hz    = 1000\nsignal_duration_s   = 1\nsignal_frequency_hz = 12\nsignal_amplitude_au = 3\n\nsampling_period     = 1/sampling_rate_hz\ntime_samples        = np.arange(0, signal_duration_s, sampling_period)\noscillatory_signal  = signal_amplitude_au * np.cos(2*np.pi*signal_frequency_hz*time_samples)\n\noscillatory_signal_with_edge = copy.copy(oscillatory_signal)\noscillatory_signal_with_edge[450:551] = 0\n\nfig, axs = plt.subplots(2,1)\naxs[0].plot(time_samples, oscillatory_signal, color=\"purple\")\naxs[1].plot(time_samples, oscillatory_signal_with_edge, color=\"purple\")\nfor ax in axs:\n    ax.set_xlabel(\"Samples\")\n    ax.set_ylabel(\"Amplitude (AU)\")\nfig.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=604 height=412}\n:::\n:::\n\n\nOur signal oscillates at 12 Hz and it's extremely clean. It only misses a small section around 500 ms, as if we had a problem with our recording machine. It happens. Because the signal is a simple oscillation, if we look at its frequency domain we should expect activity only at 12 Hz. Let's see. \n\n::: {#0fb606c1 .cell execution_count=2}\n``` {.python .cell-code}\ndef time_to_frequency_domain(signal, period):\n    fourier_complex_coefficients = fft(signal)\n    fourier_amplitudes  = np.abs(fourier_complex_coefficients[0:len(signal)//2]) / len(signal)\n    fourier_amplitudes *= 2\n    fourier_amplitudes[0] /= 2 \n    fourier_frequencies = fftfreq(len(signal), period)\n    return fourier_amplitudes, fourier_frequencies\n\noscillatory_signal_frequency_amplitude, no_edge_frequencies = time_to_frequency_domain(oscillatory_signal, sampling_period)\n\noscillatory_signal_with_edge_frequency_amplitude, edge_frequencies = time_to_frequency_domain(oscillatory_signal_with_edge, sampling_period)\n\nfig, axs = plt.subplots(2,2, gridspec_kw={'height_ratios': [1, 2]})\naxs[0,0].plot(time_samples, oscillatory_signal, color=\"purple\")\naxs[0,1].plot(time_samples, oscillatory_signal_with_edge, color=\"purple\")\naxs[1,0].stem(no_edge_frequencies[0:50], oscillatory_signal_frequency_amplitude[0:50], markerfmt=\"teal\", basefmt=\"\")\naxs[1,1].stem(edge_frequencies[0:50], oscillatory_signal_with_edge_frequency_amplitude[0:50], markerfmt=\"teal\", basefmt=\"\")\n\naxs[1,0].axvline(signal_frequency_hz, linestyle=\"--\", color=\"gray\")\naxs[1,1].axvline(signal_frequency_hz, linestyle=\"--\", color=\"gray\")\n\naxs[0,0].set_xlabel(\"Samples\")\naxs[0,1].set_xlabel(\"Samples\")\naxs[0,0].set_ylabel(\"Amplitude (AU)\")\n\naxs[1,0].set_xlabel(\"Frequency (Hz)\")\naxs[1,1].set_xlabel(\"Frequency (Hz)\")\naxs[1,0].set_ylabel(\"Amplitude (AU)\")\nfig.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=604 height=412}\n:::\n:::\n\n\nWhat do we notice? The frequency domain of the signal without any missing data is as expected. A flat line at 0 Hz across all frequencies, except for 12 Hz, the frequency of our signal. The frequency domain of the signal with the edge, instead, is less clean. Although there is a clear peak at 12 Hz, other frequencies show some amplitude too. Indeed, the amplitude at 12 Hz is less than 3 AU (the amplitude of our signal). This further suggest that the amplitude has been smeared across other frequencies. Not only that, but we see that the spectrogram has some bumps, an artefact called \"ringing\".\n\nIt is unlikely that in real data we lose long portions of the recording right in the middle of a trial. If that happens, it would also be easy, and probably wiser, to remove the trial altogether to avoid interpreting non existing data. This does not mean that we are safe from edge artefacts. Conversely, they tend to exist in every trial. Can you guess where?\n\n::: {#177b5edb .cell execution_count=3}\n``` {.python .cell-code}\nfig, ax = plt.subplots()\nax.plot(time_samples, oscillatory_signal, color=\"purple\")\nax.annotate(\"Here\",\n            xy=(0, 3), xycoords=\"data\",\n            xytext=(0.5, 3.5), textcoords=\"data\",\n            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc\", facecolor=\"black\"))\nax.annotate(\"\",\n            xy=(1, 3), xycoords=\"data\",\n            xytext=(0.56, 3.54), textcoords=\"data\",\n            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc\", facecolor=\"black\"))\nax.axis(\"off\")\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){width=495 height=364}\n:::\n:::\n\n\nExactly, at the beginning and end of each trial. In many experiments we need to divide the data into chunks (epoch) representing some period of interest (e.g. the onset of a stimulus or a response). Consequently, the beginning and end of each chunk are literal discontinuities, as the data begins and ends abruptly. For a smooth signal like the one we have been working with, this is not an issue. Moreover, we know exactly it's frequency and amplitude, so we can always verify the results and amend any edge effect. With real data the situation is tricky. Each trial is different. Edges can take many different forms and we don't know the ground truth signal; that is, we cannot be 100% sure whether the results we observe in the frequency domain are real representations of the data or artefacts. So, how do we go about this? The answer is seemingly simple, we *window* the data.\n\nIf you pay attention to the method section of papers performing frequency analyses, you might read sentences like \"a Fast Fourier Transform (FFT) was applied to the Hanning windowed data to extract the complex coefficients...\". You might read... unfortunately reporting standards are not great and many papers don't really explain properly what the did, potentially because who ran the analyses used prepackaged functions with default settings without really engaging in the process happening in the background. Anyway, what do we mean with *windowed data*? Put it simply, we multiply our data by some function that tries to smooth its edges while preserving the central part of the signal. The function we use can vary and a common one (likely because it's Matlab [pwelch](https://au.mathworks.com/help/signal/ref/pwelch.html) default) is the Hanning window. It looks like this\n\n::: {#594ecb0b .cell execution_count=4}\n``` {.python .cell-code}\ndef create_hanning_window(sample_indices, lenght):\n    z   = (2 * np.pi *  sample_indices) /  lenght\n    win = (np.cos((z - np.pi)/2))**2\n    return win\n# Generate window\nhanning_window = create_hanning_window(np.arange(100), 100)\n\nfig, ax = plt.subplots(figsize=(8.4, 5))\nax.plot(hanning_window, color=\"purple\")\nax.set_xlabel(\"Samples\")\nax.set_ylabel(\"Amplitude (AU)\")\nax.set_title(\"Hanning Window\")\n```\n\n::: {.cell-output .cell-output-display execution_count=307}\n```\nText(0.5, 1.0, 'Hanning Window')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-2.png){width=690 height=445}\n:::\n:::\n\n\nAs you can see, the window starts at 0, smoothly goes up to 1 and then smoothly goes back to zero. Now, what happens if we multiply this window with our signal? We taper the signal. The amplitude at the edges will be decreased, while the amplitude in the middle of the signal will be preserved.\n\n::: {#fbdf401a .cell execution_count=5}\n``` {.python .cell-code}\nhanning_window = create_hanning_window(np.arange(len(oscillatory_signal)), len(oscillatory_signal))\nfig, axs = plt.subplot_mosaic([[\"signal\", \"window\"], [\"result\", \"result\"]],\n                              layout='constrained')\naxs[\"signal\"].plot(time_samples, oscillatory_signal, color=\"purple\")\naxs[\"window\"].plot(time_samples, hanning_window, color=\"teal\")\naxs[\"result\"].plot(time_samples, oscillatory_signal*hanning_window, color=\"purple\")\naxs[\"result\"].plot(time_samples, hanning_window*oscillatory_signal.max(), color=\"teal\", alpha=0.25)\n\naxs[\"signal\"].set_title(\"Signal\")\naxs[\"window\"].set_title(\"Hanning Window\")\naxs[\"result\"].set_title(\"Signal x Hanning Window\")\n```\n\n::: {.cell-output .cell-output-display execution_count=308}\n```\nText(0.5, 1.0, 'Signal x Hanning Window')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-2.png){width=626 height=434}\n:::\n:::\n\n\nSuch a satisfying shape! There are 2 key elements to notice here. As noted above, the amplitude at the onset and offset of the signal is dampened. Secondly, the oscillatory frequency is not affected. So, let's see the resulting power spectrum\n\n::: {#22c23e46 .cell execution_count=6}\n``` {.python .cell-code}\nwindowed_oscillatory_signal = oscillatory_signal * hanning_window\nwindowed_oscillatory_signal_amplitudes, windowed_signal_frequencies = time_to_frequency_domain(windowed_oscillatory_signal, sampling_period)\n\nfig, ax = plt.subplots()\nax.stem(windowed_signal_frequencies[0:50], windowed_oscillatory_signal_amplitudes[0:50], markerfmt=\"teal\", basefmt=\"\")\nax.set_xlabel(\"Frequency (Hz)\")\nax.set_ylabel(\"Amplitude (AU)\")\n```\n\n::: {.cell-output .cell-output-display execution_count=309}\n```\nText(0, 0.5, 'Amplitude (AU)')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-2.png){width=541 height=383}\n:::\n:::\n\n\nAlllright. The peaks appears around the correct frequency, 12Hz. However, there are multiple peaks and... the amplitude is wrong. Remember, we expect an amplitude of 3 AU at 12 Hz. It looks like we worsened the original results in this case. It makes sense though. Let's think about this. For once, by windowing the signal we preserve the amplitude in the middle portion, but we reduce the the amplitude at the edges. Therefore,there is less total amplitude across the whole trial. Secondly, the window itself has its own representation in the frequency domain. Because the frequency domain is just a different view of the time domain, when we modify the time domain we modify the frequency domain. In other words, by multiplying a signal with a window we introduce alterations in the frequency domain. We can build an insight into this by looking at the frequency domain of the window itself\n\n::: {#ae2e7c68 .cell execution_count=7}\n``` {.python .cell-code}\nhanning_window = np.pad(hanning_window, 2000, mode='constant')\nhanning_coeff = fft(hanning_window)\nhanning_amplitudes  = np.abs(hanning_coeff) / len(hanning_window)\nhanning_amplitudes *= 2\nhanning_amplitudes[0] /= 2\nif len(hanning_window) % 2 == 0:  # Halve the Nyquist component if it exists\n    hanning_amplitudes[len(hanning_window) // 2] /= 2\n\n# Frequency axis\nhanning_frequencies = fftfreq(len(hanning_window), sampling_period)\nhanning_frequencies = fftshift(hanning_frequencies)  # Shift zero frequency to the center\nhanning_amplitudes = fftshift(hanning_amplitudes)\n\nzero_index = int(np.where(hanning_frequencies == 0)[0])\nfig, ax = plt.subplots()\nax.plot(hanning_frequencies[zero_index-100:zero_index+100], 20*np.log10(hanning_amplitudes[zero_index-100:zero_index+100]))\nax.set_xlabel(\"Frequency (Hz)\")\nax.set_ylabel(\"Amplitude (AU)\")\nprint(hanning_frequencies[1150])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-270.0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_215857/1839882223.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  zero_index = int(np.where(hanning_frequencies == 0)[0])\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-3.png){width=554 height=385}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}